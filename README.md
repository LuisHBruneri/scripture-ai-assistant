# Scripture AI Assistant ğŸ›¡ï¸ğŸ“–
> **MBA USP/Esalq - TCC Project**
> *Agente TeolÃ³gico Conversacional com Arquitetura RAG e Reranking SemÃ¢ntico*

Este projeto implementa um **Assistente TeolÃ³gico Inteligente** capaz de responder dÃºvidas doutrinÃ¡rias e bÃ­blicas com alta precisÃ£o, fidelidade teolÃ³gica e tom pastoral ("Persona"). Diferente de chats genÃ©ricos, ele opera sob o princÃ­pio *Sola Scriptura*, utilizando apenas documentos verificados (BÃ­blia, Teologia SistemÃ¡tica) como fonte de verdade.

## âœ¨ Diferenciais AcadÃªmicos
*   **ğŸ§  RAG com Reranking**: Utiliza **FlashRank** para refinar a busca vetorial (ChromaDB), garantindo que apenas os trechos semanticamente mais relevantes sejam enviados ao modelo (Precision@K otimizado).
*   **ğŸ“Š AvaliaÃ§Ã£o Quantitativa**: Validado pelo framework **RAGAS** (Retrieval Augmented Generation Assessment), medindo mÃ©tricas como *Answer Relevancy* e *Context Precision*.
*   **ğŸ”— CitaÃ§Ãµes Interativas**: Frontend Flutter com sistema de "Deep Linking" para referÃªncias bÃ­blicas. Clicar em `[GÃªnesis 1:1]` abre o texto original instantaneamente.
*   **ğŸ³ 100% Dockerized**: Backend (Python/FastAPI) e Frontend (Flutter Web/Nginx) totalmente containerizados para fÃ¡cil reproduÃ§Ã£o.

## ğŸ—ï¸ Arquitetura TÃ©cnica

```mermaid
graph LR
    User[UsuÃ¡rio (Flutter/Web)] -->|HTTPS| Nginx[Nginx Proxy :3000]
    Nginx -->|/api| API[FastAPI Backend :8000]
    API -->|Prompt| Reform[LLM: ReformulaÃ§Ã£o]
    Reform -->|Query| Vector[ChromaDB (Busca HÃ­brida)]
    Vector -->|Docs Brutos (Top 20)| Reranker[FlashRank (ms-marco-Minilm)]
    Reranker -->|Docs Refinados (Top 6)| LLM[Google Gemini 1.5 Flash]
    LLM -->|Resposta Pastoral| Streaming[SSE Stream]
    Streaming --> User
```

## ğŸš€ Como Executar (Plug & Play)

PrÃ©-requisitos: [Docker Desktop](https://www.docker.com/products/docker-desktop) instalado e uma chave de API do [Google AI Studio](https://aistudio.google.com/).

### 1. ConfiguraÃ§Ã£o
Clone o repositÃ³rio e configure sua chave:
```bash
cp .env.example .env
# Edite o arquivo .env e cole sua GOOGLE_API_KEY
```

### 2. Rodar AplicaÃ§Ã£o
Basta um Ãºnico comando para subir toda a infraestrutura (Banco, Backend e Frontend):
```bash
docker-compose up --build
```
*   **Frontend**: Acesse `http://localhost:3000` ğŸŒ
*   **Backend API**: DisponÃ­vel em `http://localhost:8001/docs` âš™ï¸

### 3. IngestÃ£o de Conhecimento
Para alimentar a "mente" do agente com novos PDFs, EPUBs ou Markdown:
1.  Coloque os arquivos na pasta `source_docs/`.
2.  Execute o script de ingestÃ£o:
    ```bash
    ./scripts/refresh_knowledge.sh
    # Ou via Docker: docker-compose exec backend python data_ingestion/ingest.py
    ```

## ğŸ“Š AvaliaÃ§Ã£o de Performance
O projeto inclui um pipeline de avaliaÃ§Ã£o automatizado (`evaluation/`).

| MÃ©trica | Resultado (MÃ©dia) | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| **Answer Relevancy** | **0.75** | Alta aderÃªncia Ã  pergunta do usuÃ¡rio. |
| **LatÃªncia MÃ©dia** | **~2.5s** | Tempo para o primeiro token (TTFT). |

Para reproduzir os testes:
```bash
docker-compose exec backend python evaluation/run_eval.py
```
Isso gerarÃ¡ novos grÃ¡ficos em `evaluation/charts/`.

## ğŸ› ï¸ Stack TecnolÃ³gica
*   **LLM**: Google Gemini 1.5 Flash
*   **Vector Store**: ChromaDB
*   **Reranker**: FlashRank (On-CPU)
*   **Backend**: Python 3.12, FastAPI, LangChain
*   **Frontend**: Flutter 3.x (Web & Mobile)
*   **Infra**: Docker Compose

## ğŸ“„ LicenÃ§a
Projeto acadÃªmico desenvolvido para fins de pesquisa e conclusÃ£o de curso (MBA Data Science & Analytics - USP/Esalq).